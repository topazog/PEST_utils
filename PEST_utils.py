import numpy as np
import pandas as pd
import os
import socket
import subprocess as sp
import multiprocessing as mp
import shutil
import time
import flopy

def zone_based_par(model_ws,plist,sim,zone_array,nlay=None):

    """parameterize one or several parameter types based, for all model layers, based on parameter input files

    Args:
        model_ws ('str'): working folder
        plist ('Dict'): dictionary with the parameter names as keys and the parameter file names as values. Important
        to note that the parameter files for each layer are generated by the file name value plus the layer number. For
        example, if the parameter file name is "kx_.dat", then for layer 1 the complete parameter name will be "kx_1.dat".
        sim ('Flopy'): Flopy model object
        zone_array ('np array'): parameter zone array
        nlay ('int', optional): Number of model layers. Defaults to None.

        parameter list exammple: plist = {"kx":["kx_.dat"],"vani":["vani_.dat"],"ss":["ss_.dat"],"sy":["ss_.dat"]}

    Returns:
        'list': list of template and input model file names
    """

    if nlay == None:
        nlay = sim.nlay

    nrow = sim.nrow
    ncol = sim.ncol

    par_tplfiles = []
    par_datfiles = []

    for par, paritems in plist.items():

        for ilay in range(nlay):
            if nlay == 1:
                ilay_text =""
            else:
                ilay_text =str(ilay+1)

            ipar_tplfile = paritems[0].split('.')[0]+ilay_text+".tpl"
            ipar_datfile = paritems[0].split('.')[0]+ilay_text+".dat"
            par_tplfiles.append(ipar_tplfile)
            par_datfiles.append(ipar_datfile)
            with open(os.path.join(model_ws,ipar_tplfile),'w') as f:
                f.write('ptf ~\n')
                for irow in range(nrow):
                    for icol in range(ncol):
                        izone = int(zone_array[ilay,irow,icol])
                        if izone > 0:
                            ipar = par+str(izone)
                            ipar_len = len(ipar)
                            tpl = "~" + " " * (12 - ipar_len) + ipar + "~"
                            f.write(tpl+" ")
                        else:
                            f.write("%10.8E" % (1)+" ")
                    f.write('\n')
                f.close()

    return par_tplfiles,par_datfiles

def gen_constants_par(model_ws,plist,nrow=None,ncol=None):
    """
    Generate tpl files for constant parameters

    :param plist: list of parameter and associated model files
    :return: list of template files
    """

    par_tplfiles = []

    for par, paritems in plist.items():

        par_len = len(par)
        tpl = "~" + " " * (15 - par_len) + par + "~"

        with open(os.path.join(model_ws,paritems[0]), 'r') as f:
            lines =  f.readlines()
            nnodes = len(lines)
        f.close()

        ipar_tplfile = paritems[0].split('.')[0]+".tpl"
        par_tplfiles.append(ipar_tplfile)

        with open(os.path.join(model_ws,ipar_tplfile),'w') as f:
            f.write('ptf ~\n')
            if nrow == None:
                for i in range(nnodes):
                    f.write(tpl+'\n')
            else:
                for irow in range(nrow):
                    for icol in range(ncol):
                        f.write(tpl+" ")
                    f.write('\n')
        f.close()    


    return par_tplfiles

def setup_par_grid(model_ws, sim,ibound, par_dict):

    """Setup a cell by cell multiplier parametrization for a structured MODFLOW grid. 
    It is assumed that this parameterization will be implemented in layered-based external files.

    Args:
        sr ('flopy.utils.reference.SpatialReference', optional):  a spatial reference use to
            locate the model grid in space.  If None, `ml` must not be None.  Default is None
        ibound ('numpy.ndarray'): the modflow ibound integer array.  This is used to
            set parameters only in active cells and separate between zones.
        par_dict ('dict'): a dictionary of parameter, parameter external files, and layer index
        
        Example:
        
        par_dict = {"kx":["kx.dat",[0,1,2]],"ss":["ss.dat",[1,2]], "sy":["sy.dat",[0]]}

    TODO:
        Add all exemptions

    """

    nrow = sim.nrow
    ncol = sim.ncol

    xcentergrid = sim.modelgrid.get_xcellcenters_for_layer(0)
    ycentergrid = sim.modelgrid.get_ycellcenters_for_layer(0)

    par_tplfiles = []
    par_datfiles = []
    par_points = []

    for par, paritems in par_dict.items():

        ilay = 0

        ipar_index = 1

        #par_points = []

        for ilay in paritems[1]:
            ipar_tplfile = paritems[0].split('.')[0]+"g_"+str(ilay+1)+".tpl"
            ipar_datfile = paritems[0].split('.')[0]+"g_"+str(ilay+1)+".dat"
            par_tplfiles.append(ipar_tplfile)
            par_datfiles.append(ipar_datfile)

            with open(os.path.join(model_ws,ipar_tplfile),'w') as f:
                f.write('ptf ~\n')
                for irow in range(nrow):
                    for icol in range(ncol):
                        iibound = int(ibound[ilay,irow,icol])
                        if iibound > 0:
                            ixp = xcentergrid[irow,icol]
                            iyp = ycentergrid[irow,icol]
                            ipar = par+str(ipar_index)
                            ipar_len = len(ipar)
                            tpl = "~" + " " * (12 - ipar_len) + ipar + "~"
                            f.write(tpl+" ")
                            par_points.append([ipar_index,ixp,iyp,ilay+1,par,iibound,ipar])
                            ipar_index = ipar_index+1
                        else:
                            f.write("%10.8E" % (1)+" ")
                    f.write('\n')   
                f.close()

            with open(os.path.join(model_ws,ipar_datfile),'w') as f:
                for irow in range(nrow):
                    for icol in range(ncol):
                        f.write("%10.8E" % (1)+" ")
                    f.write('\n')   
                f.close()
        
            #with open(os.path.join(model_ws,par_filename),'w') as f:
            #    for ipp in  par_points:
            #        f.write(f'{ipp[0]} {ipp[1]} {ipp[2]} {ipp[3]} {ipp[4]} {ipp[5]}\n')
            #f.close()
            
    return par_tplfiles,par_datfiles  

def gen_ppoints(model_ws,plist, spacing, ix, iy, lx, ly, gsf_file, gsf_dim, nrow=None, ncol=None,trans_f_dict=None,Mult=True):
    """Create a list of regularly spaced pilot points, in a rectangular grid,
    for use with PEST and PLPROC for MODFLOW-6 DISV.
    It also creates a simple PLPROC script and tpl file with a constant zone
    to generate kriging factors for a mf6 DISV grid

    Args:
        plist ('list'): list of parameter names, model files, and variogram range)
        spacing ('int'): spacing between pilot points
        lx ('int'): model horizontal length
        ly ('int'): model vertical length
        gsf_file('str'): mf6 gsf
        gsf_dim('int'): gsf dimensions
        nrow('int'): optional, number of rows of and structured modflow model
        ncol('int'): optional, number of columns of and structured modflow model
        trans_f_dict('dict'): optional, dictionary of hydraulic parameters with trans_option and trans parameters

        transformation functions (trans_f):
        Trans N1 = par+a*(1/(1+b**(-(par+c))))

        example of trans_f dictionary:

        trans_f_dict = {"k":[1,6,1e6,4.68]}

    Returns:
        writes pilot points tpl and dat files, and ppoints list
    """

    pp_tplfiles = []
    pp_datfiles = []
    ppoints_tpl = []
    ppoints = []

    plproc_files = []

    xp = np.arange(ix, lx+1, spacing)
    yp = np.arange(iy, ly+1, spacing)

    for par, paritems in plist.items():

        modfile = paritems[0]
        arange = paritems[1]
        transform = paritems[2]

        with open(os.path.join(model_ws,modfile), 'r') as f:
            lines =  f.readlines()
            nnodes = len(lines)
        f.close()

        if nrow == None:
            nnodes = nnodes
        else:
            nnodes = nrow*ncol

        ipp_tplfile = "pp_" + par + ".tpl"
        ipp_datfile = "pp_" + par + ".dat"
        pp_tplfiles.append(ipp_tplfile)
        pp_datfiles.append(ipp_datfile)

        iplproc_files=[]

        iplproc_files.append("plproc_" + par + "_factors.dat")
        plproc_files.append("plproc_" + par + "_factors.dat")
        iplproc_files.append("plproc_" + par + "_krige.dat")
        plproc_files.append("plproc_" + par + "_krige.dat")

        index = 0

        ippoints_tpl=[]
        ippoints = []

        with open(os.path.join(model_ws,ipp_tplfile),'w') as f:
            f.write('ptf ~\n')
            for ixp in xp:
                for iyp in yp:
                    parname_tx = str(par + "_pp") + str(index+1)
                    parname_len = len(parname_tx)
                    tpl = "~" + " " * (13 - parname_len) + parname_tx + "~"
                    ippoints_tpl.append([index+1, ixp, iyp, 1, tpl, parname_tx])
                    ippoints.append([index+1, ixp, iyp, 1, 1.0, parname_tx])
                    for item in ippoints_tpl[index]:
                        f.write(str(item) + " " * (18 - len(str(item))))
                    f.write('\n')
                    index = index+1
        f.close()

        ppoints_tpl.append(ippoints_tpl)
        ppoints.append(ippoints)

        plproc_tpl = par + "_plproc.tpl"

        if nrow==None:
            with open(os.path.join(model_ws,plproc_tpl), 'w') as f:
                f.write("$#p " + par + "r.write_in_sequence(number_per_line=1,start_index=1,end_index=" + str(
                    nnodes) + ")")
            f.close()
        else:
            with open(os.path.join(model_ws,plproc_tpl), 'w') as g:
                g.write("$#p " + par + "r.write_in_sequence(number_per_line="
                +str(ncol)+",start_index=1,end_index=" + str(
                nrow*ncol) + ")")
            g.close() 

        with open(os.path.join(model_ws,ipp_datfile), 'w') as f:
            for items in ippoints:
                for item in items:
                    f.write(str(item) + " " * (14 - len(str(item))))
                f.write('\n')
        f.close()


        for i in range(len(iplproc_files)):
            with open(os.path.join(model_ws,iplproc_files[i]), 'w') as f:
                f.write("# grid spec file " + '\n')
                f.write("mf_grid = read_mf6_grid_specs(file='" + gsf_file + "',dimensions=" + str(gsf_dim) + ")" + '\n')
                f.write("\n")
                f.write("# pilot point file " + '\n')
                f.write(
                    "cl_pp = read_list_file(dimensions=" + str(gsf_dim) + ",plist=pp_" + par + ";column=5, &" + '\n')
                f.write("       id_type=indexed,file='" + ipp_datfile + "',skiplines=0)" + '\n')
                f.write("\n")
                if i == 0:
                    f.write("# Kriging factors calculation " + '\n')
                    f.write("calc_kriging_factors_2d(target_clist=mf_grid, source_clist=cl_pp, &" + '\n')
                    f.write("       file=factors_" + par + ".dat,variogram=exponential, &" + '\n')
                    f.write("       a=" + str(arange) + ",kriging=simple, min_points=3,max_points=12, &" + '\n')
                    f.write("       search_radius=" + str(arange * 10) + ")" + '\n')
                    f.write("\n")
                f.write("# Kriging for pilot points parameters " + '\n')

                if Mult:
                    f.write(par + "r=new_plist(reference_clist=mf_grid, value=1.0e+31)" + '\n')
                    f.write(par + "l=new_plist(reference_clist=mf_grid, value=1.0)" + '\n')
                    f.write(par + "r.read_list_as_array(file=" + modfile + ", &" + '\n')
                    f.write("start_index = 1, end_index =" + str(nnodes) + ",line = 1)" + '\n')
                    f.write(par + "l=pp_" + par + ".krige_using_file(file='factors_"
                            + par + ".dat',mean=1.0, transform="+transform+")\n")
                    f.write(par + "r= " + par + "r*" + par + "l" + '\n')
                else:
                    f.write(par + "r=new_plist(reference_clist=mf_grid, value=1.0e+31)" + '\n')
                    f.write(par + "r=pp_" + par + ".krige_using_file(file='factors_"
                            + par + ".dat',mean=1.0, transform="+transform+")\n") 
                if par == "sy":
                    f.write(par + "r=min(" + par + "r*" + par + "l,0.99)" + '\n')
                if trans_f_dict!=None:
                    for tpar, tparitems in trans_f_dict.items():
                        trans_f = tparitems[0]
                        if trans_f == 1:
                            a = str(tparitems[1])
                            b = str(tparitems[2])
                            c = str(tparitems[3])
                            if tpar == par:
                                ipar = par + "r"
                                f.write(f"{ipar} = 10**(log10({ipar}) + {a}*(1/(1+{b}**(-(log10({ipar})+{c})))))\n")
                f.write("write_model_input_file(template_file=" + par + "_plproc.tpl,model_input_file="+modfile+')\n')
                        
            f.close()

        cwd = os.getcwd()

        os.chdir(model_ws)
        
        plproc_ins = "plproc.exe " + iplproc_files[0]
        os.system(plproc_ins)

        os.chdir(cwd)

    return pp_tplfiles, pp_datfiles, plproc_files, ppoints_tpl

def setup_plproc_auto2D(model_ws,gsf_filename,sim,plist,unit_dict,zone_array,every_n_cell=None,truncate_values=None):
    """Creates 2D pilot points and PLPROC script for a structured modflow-USG grid, using zones. 
       

    Args:
        model_ws ('str'): model working folder
        gsf_filename ('str'): grid spec file
        plist ('lst'): parameter list with asociated layers to include
        zone_array('np array'): model zone array
        unit_dict('Dict'): dictionary with min and max values for each zone, for each parameter


    Returns:

    Example:
        
    """

    # Zone files, one for each layer, are created from zone_array

    zone_files = []

    for ilay in range(zone_array.shape[0]):
        filename = "zone_L"+str(ilay+1)+".dat"
        np.savetxt(os.path.join(model_ws,filename),zone_array[ilay])
        zone_files.append(filename)

    xcentergrid = sim.modelgrid.get_xcellcenters_for_layer(0)
    ycentergrid = sim.modelgrid.get_ycellcenters_for_layer(0)

    nrow = sim.nrow
    ncol= sim.ncol

    pp_tplfiles = [] # list of pp_tpl file names
    pp_datfiles = [] # list of corresponding pp_dat file names
    ppoints_tpl = []

    plproc_files = []

    # unique zones from zone_array

    model_zones = np.unique(zone_array)

    # 2D array for each zone (ones and zeros)

    zone_2d = np.zeros((len(model_zones),sim.nrow,sim.ncol),dtype=int)
    for izone in range(len(model_zones)):
        for ilay in range(sim.nlay):
            zone_2d[izone][zone_array[ilay]==model_zones[izone]]=1

    # iterate for each parameter

    ppoints=[]

    g_index = 0

    t=0

    for par,paritems in plist.items():

        if len(truncate_values)==1:
            trunc = truncate_values[0]
        else:
            trunc = truncate_values[t]
            t=t+1

        ipp_tplfile = "pp_" + par + ".tpl"
        ipp_datfile = "pp_" + par + ".dat"
        pp_tplfiles.append(ipp_tplfile)
        pp_datfiles.append(ipp_datfile)

        if every_n_cell == None:
            every_n_cell = 10

        ippoints_tpl=[]
        ippoints=[]
        

        #index for each pilot point
        l_index = 0

        for i in range(len(model_zones)):

            if model_zones[i] != 0:

                start = int(float(every_n_cell) / 2.0)
                izone=model_zones[i]

                j=0

                for irow in range(start,zone_array.shape[1]-start,every_n_cell):
                    for icol in range(start,zone_array.shape[2]-start,every_n_cell):
                        if zone_2d[i][irow,icol]==0:
                            continue
                        j = 1
                        ixp = xcentergrid[irow,icol]
                        iyp = ycentergrid[irow,icol]
                        parname_tx = par + "_"+"pp"+ str(l_index+1)
                        parname_len = len(parname_tx)
                        ppoints.append([g_index+1, ixp, iyp, par, izone, parname_tx])
                        ippoints.append([l_index+1, ixp, iyp, par, izone, parname_tx])
                        g_index = g_index+1
                        l_index = l_index+1
            
                if j==0:
                    irow = np.where(zone_2d[i]==1)[0][0]
                    icol = np.where(zone_2d[i]==1)[1][0]
                    ixp = xcentergrid[irow,icol]
                    iyp = ycentergrid[irow,icol]
                    parname_tx = par +"_"+"pp"+ str(l_index+1)
                    
                    ppoints.append([g_index+1, ixp, iyp, par, izone, parname_tx])
                    ippoints.append([l_index+1, ixp, iyp, par, izone, parname_tx])

                    g_index = g_index+1
                    l_index = l_index+1

        #creation of ppoint dat and template file

        with open(os.path.join(model_ws,ipp_datfile),'w') as f:
            for i in range(len(ippoints)):
                index = ippoints[i][0]
                ixp=ippoints[i][1]
                iyp=ippoints[i][2]
                izone=int(ippoints[i][4])
                parname_tx = ippoints[i][5]
                parname_len = len(parname_tx)
                value = 1.0
                f.write(f'{index} {ixp} {iyp} {izone} {value} {parname_tx}\n')
        f.close()

        with open(os.path.join(model_ws,ipp_tplfile),'w') as f:
            f.write('ptf ~\n')
            for i in range(len(ippoints)):
                index = ippoints[i][0]
                ixp=ippoints[i][1]
                iyp=ippoints[i][2]
                izone=int(ippoints[i][4])
                parname_tx = ippoints[i][5]
                parname_len = len(parname_tx)
                tpl = "~" + " " * (15 - parname_len) + parname_tx + "~"
                ippoints_tpl.append([index+1, ixp, iyp, izone, tpl, parname_tx])
                f.write(f'{index} {ixp} {iyp} {izone} {tpl} {parname_tx}\n')
        f.close()

        iplproc_files=[]

        iplproc_files.append("plproc_" + par + "_factors.dat")
        plproc_files.append("plproc_" + par + "_factors.dat")
        iplproc_files.append("plproc_" + par + "_krige.dat")
        plproc_files.append("plproc_" + par + "_krige.dat")

        for i in range(len(iplproc_files)):
            with open(os.path.join(model_ws,iplproc_files[i]), 'w') as f:

                f.write("# grid spec file " + '\n')
                f.write("mf_grid = read_mf_grid_specs(file='" + gsf_filename + "')" + '\n')
                f.write("\n")

                for ilay in range(sim.nlay):
                    f.write("zoneL"+str(ilay+1)+"=read_mf_int_array(reference_clist='mf_grid', &\n")
                    f.write("file="+zone_files[ilay]+")\n")
                f.write("\n")

                f.write("# pilot point file " + '\n')
                f.write("cl_pp = read_list_file(dimensions=" + str(2) + ", &\n")
                f.write("slist='zone_"+par+"';column=4, &\n")
                f.write("plist=pp_" + par + ";column=5, &" + '\n')
                f.write("id_type=indexed,file='" + ipp_datfile + "',skiplines=0)" + '\n')
                f.write("\n")
                if i == 0:
                    f.write("# Kriging factors calculation " + '\n')
                    for ilay in range(sim.nlay):
                        layer=ilay+1
                        pp_zones = []
                        zone = zone_array[ilay]
                        un_zones = np.unique(zone)
                        for un_zone in un_zones:
                            if un_zone > 0:
                                pp_zones.append(int(un_zone))  
                        for ppzone in pp_zones:
                            factor_file = "factors_" + par +"l"+str(layer)+"_z"+str(ppzone)+".dat"
                            f.write("calc_kriging_factors_auto_2d(target_clist=mf_grid;select=(zoneL"+str(layer)
                            +"=="+str(ppzone)+"), &\n")
                            f.write("source_clist=cl_pp;select=(zone_"+ par +"=="+str(ppzone)+"), &\n")
                            f.write("file="+factor_file+",kriging=ordinary)\n")
                            f.write("\n")
                f.write("# Kriging for pilot points parameters " + '\n')
                for ilay in range(sim.nlay):
                    layer=ilay+1
                    ipar = par + "_"+str(layer)

                    par_f = []

                    for k in range(len(paritems)):
                        f.write(ipar+"f"+str(k+1)+"=new_plist(reference_clist=mf_grid, value=1.0e+31)" + '\n')
                        modfile = paritems[k].split('.')[0]+ str(layer)+".dat"
                        f.write(ipar+"f"+str(k+1)+".read_list_as_array(file=" + modfile+", &" + '\n')
                        f.write("start_index = 1, end_index =" + str(nrow*ncol) + ",line = 1)" + '\n')
                        par_f.append(ipar+"f"+str(k+1))

                    if len(par_f) == 1:
                        mult_f = par_f[0]
                    else:
                        mult_f = par_f[0]
                        for k in range(1,len(par_f)):
                            mult_f = mult_f+"*"+par_f[k]
                    
                    f.write(ipar+"=new_plist(reference_clist=mf_grid, value=1.0e+31)" + '\n')
                    f.write(ipar+"="+mult_f+"\n")

                    f.write(ipar+"l=new_plist(reference_clist=mf_grid, value=1.0e+00)" + '\n')
   
                    pp_zones = []
                    zone = zone_array[ilay]
                    un_zones = np.unique(zone)
                    for un_zone in un_zones:
                        if un_zone > 0:
                            pp_zones.append(int(un_zone))  
                    for ppzone in pp_zones:
                        factor_file = "factors_" + par +"l"+str(layer)+"_z"+str(ppzone)+".dat"
                        f.write(ipar+ "l=pp_"+ par + ".krige_using_file(file='"+factor_file+"', transform=log)\n")
                        f.write(ipar+"="+ipar+"*"+ipar+"l\n")
                        ipar_sel = ipar+"(select=("+"zoneL"+str(layer)+"=="+str(ppzone)+"))"
                        if trunc:
                            min_value = str(unit_dict[ppzone][par+"_min"])
                            max_value = str(unit_dict[ppzone][par+"_max"])
                            f.write(ipar_sel+"=max("+ipar+","+min_value+")\n")
                            f.write(ipar_sel+"=min("+ipar+","+max_value+")\n")
                        
                    plproc_tpl =  ipar + "_plproc.tpl"

                    with open(os.path.join(model_ws,plproc_tpl), 'w') as g:
                         g.write("$#p " + ipar + ".write_in_sequence(number_per_line="
                        +str(ncol)+",start_index=1,end_index=" + str(
                        nrow*ncol) + ")")
                    g.close() 

                    model_input_file = paritems[0].split('.')[0]+str(layer)+"."+paritems[0].split('.')[1]
                
                    f.write("write_model_input_file(template_file=" + ipar + "_plproc.tpl,model_input_file="+model_input_file+')\n')
            f.close()

        cwd = os.getcwd()

        os.chdir(model_ws)

        plproc_ins = "plproc.exe " + iplproc_files[0]
            
        os.system(plproc_ins)

        os.chdir(cwd)

    #par_pp_df = pd.DataFrame(ppoints,columns=['par_loc_index','x','y','par_type','zone','parname'])

    return pp_tplfiles, pp_datfiles, plproc_files, ppoints_tpl

def setup_plproc_auto2D_mf6(model_ws,nrow, ncol,gsf_filename, gsf_dim,plist,zone_files):
    """Creates PLPROC script and updated the lpf package for a structured
        modflow grid, using zones.

    Args:
        model_ws ('str'): model working folder
        gsf_filename ('str'): grid spec file
        gsf_dim('int'): dimensions of the gsf_file
        plist ('lst'): parameter list with asociated layers to include
        pp_files ('str'): pilot point files
        zone_files('str'): model zone files (one for each layer)

    Returns:
        
    """

    pp_tplfiles = []
    pp_datfiles = []
    ppoints_tpl = []

    plproc_files = []

    for par,paritems in plist.items():

        ppfile = paritems[0]
        pplayers = paritems[1]

        ipp_tplfile = "pp_" + par + ".tpl"
        ipp_datfile = "pp_" + par + ".dat"
        pp_tplfiles.append(ipp_tplfile)
        pp_datfiles.append(ipp_datfile)

    # se cargan los archivos de zonas de pp y se guardan en arreglo

        sel_zone_files = []
        

        for pplayer in pplayers:
            sel_zone_files.append(zone_files[pplayer]) 

        with open(os.path.join(model_ws,ppfile),'r') as f:
            lines = f.readlines()
        f.close()

        ippoints_tpl=[]
        index = 0

        #creation of ppoint template file

        with open(os.path.join(model_ws,ppfile.split('.')[0]+".tpl"),'w') as f:
            f.write('ptf ~\n')
            for line in lines:
                parname_tx = str(par + "_pp") + str(index+1)
                parname_len = len(parname_tx)
                tpl = "~" + " " * (10 - parname_len) + parname_tx + "~"
                line_items = line.split()
                ixp=float(line_items[1])
                iyp=float(line_items[2])
                izone=int(line_items[3])
                ippoints_tpl.append([index+1, ixp, iyp, izone, tpl, parname_tx])
                for item in ippoints_tpl[index]:
                    f.write(str(item) + " " * (14 - len(str(item))))
                f.write('\n')
                index = index+1 
        f.close()

        ppoints_tpl.append(ippoints_tpl)

        iplproc_files=[]

        iplproc_files.append(os.path.join(model_ws,"plproc_" + par + "_factors.dat"))
        plproc_files.append(os.path.join(model_ws,"plproc_" + par + "_factors.dat"))
        iplproc_files.append(os.path.join(model_ws,"plproc_" + par + "_krige.dat"))
        plproc_files.append(os.path.join(model_ws,"plproc_" + par + "_krige.dat"))

        for i in range(len(iplproc_files)):
            with open(iplproc_files[i], 'w') as f:

                f.write("# grid spec file " + '\n')
                f.write("mf_grid = read_mf6_grid_specs(file='" + gsf_filename + "',dimensions=" + str(gsf_dim) + ")" + '\n')
                f.write("\n")

                for ilay in range(len(pplayers)):
                    f.write("zoneL"+str(pplayers[ilay]+1)+"=read_mf_int_array(reference_clist='mf_grid', &\n")
                    f.write("file="+sel_zone_files[ilay]+")\n")
                f.write("\n")

                f.write("# pilot point file " + '\n')
                f.write("cl_pp = read_list_file(dimensions=" + str(2) + ", &\n")
                f.write("slist='zone_"+par+"';column=4, &\n")
                f.write("plist=pp_" + par + ";column=5, &" + '\n')
                f.write("id_type=indexed,file='" + ppfile + "',skiplines=0)" + '\n')
                f.write("\n")
                if i == 0:
                    f.write("# Kriging factors calculation " + '\n')
                    for ilay in range(len(pplayers)):
                        layer=pplayers[ilay]+1
                        pp_zones = []
                        zone = np.loadtxt(os.path.join(model_ws,sel_zone_files[ilay]))
                        un_zones = np.unique(zone)
                        for un_zone in un_zones:
                            if un_zone > 0:
                                pp_zones.append(int(un_zone))  
                        for ppzone in pp_zones:
                            factor_file = "factors_" + par +"l"+str(layer)+"_z"+str(ppzone)+".dat"
                            f.write("calc_kriging_factors_auto_2d(target_clist=mf_grid;select=(zoneL"+str(layer)
                            +"=="+str(ppzone)+"), &\n")
                            f.write("source_clist=cl_pp;select=(zone_"+ par +"=="+str(ppzone)+"), &\n")
                            f.write("file="+factor_file+",kriging=ordinary)\n")
                            f.write("\n")
                f.write("# Kriging for pilot points parameters " + '\n')
                for ilay in range(len(pplayers)):
                    layer=pplayers[ilay]+1
                    ipar = par + "l"+str(layer)
                    f.write(ipar+"=new_plist(reference_clist=mf_grid, value=1.0e+31)" + '\n')
                    modfile = ipar+".dat"
                    f.write(ipar+".read_list_as_array(file=" + modfile + ", &" + '\n')
                    f.write("start_index = 1, end_index =" + str(nrow*ncol) + ",line = 1)" + '\n')    
                    pp_zones = []
                    zone = np.loadtxt(os.path.join(model_ws,sel_zone_files[ilay]))
                    un_zones = np.unique(zone)
                    for un_zone in un_zones:
                        if un_zone > 0:
                            pp_zones.append(int(un_zone))  
                    for ppzone in pp_zones:
                        factor_file = "factors_" + par +"l"+str(layer)+"_z"+str(ppzone)+".dat"
                        f.write(ipar+ "=pp_" + par + ".krige_using_file(file='"+factor_file+"', transform=log)\n")
                        
                    plproc_tpl =  ipar + "_plproc.tpl"

                    with open(os.path.join(model_ws,plproc_tpl), 'w') as g:
                         g.write("$#p " + ipar + ".write_in_sequence(number_per_line="
                        +str(ncol)+",start_index=1,end_index=" + str(
                        nrow*ncol) + ")")
                    g.close() 
                
                    f.write("write_model_input_file(template_file=" + ipar + "_plproc.tpl,model_input_file="+modfile+')\n')
            f.close()

            cwd = os.getcwd()

            os.chdir(model_ws)


            plproc_ins = "plproc.exe " + "plproc_k_krige.dat"
            
            os.system(plproc_ins)

            os.chdir(cwd)

    return pp_tplfiles, pp_datfiles, plproc_files, ppoints_tpl

def mf6obs2smp(model_ws,csv_file, date, mindate, maxdate, noise, filename):
    """create a classic smp file from a mf6 observation file
    this has been partially copied from the pyemu replace_time_with_datetime function
    included in helpers.py

    Args:
        csv_file ('str'): original mf6 observation filr
        date ('str'): initial date in DD-MM-YYYY format
        mindate ('str'): min date for data filtering
        maxdate ('str'): max date for data filtering
        noise (double): noise to add to the data
        filename ('str'): output smp file name

    Returns:
        smp file in classic PEST format (WELLID, DATE, TIME, OBSERVATION VALUE)
    """

    start_datetime = pd.to_datetime(date)
    min_datetime = pd.to_datetime(mindate)
    max_datetime = pd.to_datetime(maxdate)

    df = pd.read_csv(csv_file, index_col=0)
    df.loc[:, "datetime"] = start_datetime + pd.to_timedelta(np.round(df.index.values, 4), unit='d')
    df.index = df.pop("datetime")
    df = df.loc[~df.index.duplicated(keep="last"), :]

    if mindate == None:
        if maxdate == None:
            df_filt = df
        else:
            df_filt = df.loc[:max_datetime]
    else:
        if maxdate == None:
            df_filt = df.loc[min_datetime:]
        else:
            df_filt = df.loc[min_datetime:max_datetime]

    with open(os.path.join(model_ws,filename), 'w') as f:
        for column in df_filt.columns:
            for icount in range(len(df_filt[column])):
                idate = f"{df_filt.index[icount]:%d/%m/%Y %H:%M:%S}"
                obsvalue = f"{df_filt[column][icount]+np.random.normal(0, noise, 1)[0]:.7f}"
                f.write(column + " " + idate + " " + obsvalue)
                f.write('\n')

    return filename, df_filt

def pestprep1(model_ws,pstfile, obsfile, simfile,prefix,obsgroupname, tplfiles, batch_file):
    """
    :param pstfile: pst file to be created
    :param obsfile: observation file
    :param simfile: simulated counterpart file
    :param tplfiles: list of tpl files
    :param parfiles: list of par files
    :param obsgroupname: name of observation group
    :return: pst file
    """
    ntplfiles = len(tplfiles)

    cwd = os.getcwd()

    os.chdir(model_ws)

    with open("pestprep1.in", 'w') as f:
        f.write(obsfile + '\n')
        f.write(simfile + '\n')
        f.write(prefix + '\n')
        f.write("b" + '\n')
        f.write("f" + '\n')
        f.write(obsgroupname + '\n')
        f.write(simfile.split('.')[0] + ".ins" + '\n')
        f.write(str(ntplfiles) + '\n')
        for ifile in tplfiles:
            f.write(ifile + '\n')
            f.write(ifile.split('.')[0] + ".dat" + '\n')
        f.write(pstfile + '\n')
        f.write(batch_file)

    os.system("pestprep1.exe < pestprep1.in")

    os.chdir(cwd)

    return pstfile

def pestprep1b(model_ws,pstfile, obsfile, simfile, prefix,obsgroupname, tplfiles,inpfiles, batch_file):
    """
    :param pstfile: pst file to be created
    :param obsfile: observation file
    :param simfile: simulated counterpart file
    :param tplfiles: list of tpl files
    :param inpfiles: list of input files associated with the tpl files
    :param obsgroupname: name of observation group
    :return: pst file
    """
    cwd = os.getcwd()

    os.chdir(model_ws)

    ntplfiles = len(tplfiles)

    with open("pestprep1.in", 'w') as f:
        f.write(obsfile + '\n')
        f.write(simfile + '\n')
        f.write(prefix + '\n')
        f.write("b" + '\n')
        f.write("f" + '\n')
        f.write(obsgroupname + '\n')
        f.write(simfile.split('.')[0] + ".ins" + '\n')
        f.write(str(ntplfiles) + '\n')
        for ifile in range(len(tplfiles)):
            f.write(tplfiles[ifile] + '\n')
            f.write(inpfiles[ifile] + '\n')
        f.write(pstfile + '\n')
        f.write(batch_file)

    os.system("pestprep1.exe < pestprep1.in")

    os.chdir(cwd)

    return pstfile

def pestprep2(model_ws,or_pst, obsfile, simfile,prefix, obsgroupname, new_pst):
    """
    :param or_pst: original pst file
    :param obsfile: observation file
    :param simfile: simulated counterpart file
    :param obsgroupname: name of observation group
    :param new_pst: new pst file
    :return: pst file
    """

    cwd = os.getcwd()

    os.chdir(model_ws)

    with open("pestprep2.in", 'w') as f:
        f.write(obsfile + '\n')
        f.write(simfile + '\n')
        f.write(prefix + '\n')
        f.write("b" + '\n')
        f.write("f" + '\n')
        f.write(obsgroupname + '\n')
        f.write(simfile.split('.')[0] + ".ins" + '\n')
        f.write(or_pst + '\n')
        f.write(new_pst + '\n')

    os.system("pestprep2.exe < pestprep2.in")

    os.chdir(cwd)

    return new_pst

def wtfactor(model_ws,or_pst, obsgroupname, factor, new_pst):
    """

    :param or_pst: original pst file
    :param obsgroupname: observation group
    :param factor: factor to apply to original weights
    :param new_pst: new pst with the adjusted weights
    :return: new pst
    """
    cwd = os.getcwd()

    os.chdir(model_ws)

    wtfactor_ins = "wtfactor.exe"+" "+or_pst+" "+obsgroupname+" "+str(factor)+" "+new_pst

    os.system(wtfactor_ins)

    os.chdir(cwd)

    return new_pst

def pstpargroup(model_ws,or_pst,new_pst,upargroups=None):
    """
    Update the parameter groups of a pst files

    :param or_pst: original pst file
    :param upargroups: updated parameter group list and associated PEST parameters
    :param new_pst: new pst file
    :return: pst file
    """

    cwd = os.getcwd()

    os.chdir(model_ws)

    with open(or_pst,'r') as f:
        lines = f.readlines()
    f.close()

    line = lines[3].split()
    npar = int(line[0])
    nobs = int(line[1])
    npargroups = int(line[2])
    nregeq = int(line[3])
    nobsgroups = int(line[4])

    if upargroups != None:
        nupargroups =len(upargroups)
    else:
        upargroups = []
        icount = 0
        for line in range(icount+1,len(lines)):
            if lines[line] == "* parameter data\n":
                icount=line
                break
        for i in range(icount + 1, icount + 1+npar):
            paritems = lines[i].split()
            par = paritems[0]
            ipargroup = par.rstrip('0123456789')
            rep = 0
            for iupargroup in upargroups:
                if iupargroup[0] == ipargroup:
                    rep = 1
            if rep == 0:
                upargroups.append([ipargroup,"relative",0.01,0.0,"switch",2.0,"parabolic"])
        nupargroups =len(upargroups)

    iline = 0
    icount = 0
    with open(new_pst,'w') as f:
        f.write(lines[0])
        f.write(lines[1])
        f.write(lines[2])
        f.write(str(npar) + " " * (10 - len(str(npar))))
        f.write(str(nobs) + " " * (10 - len(str(nobs))))
        f.write(str(nupargroups) + " " * (10 - len(str(nupargroups))))
        f.write(str(nregeq) + " " * (10 - len(str(nregeq))))
        f.write(str(nobsgroups) + " " * (10 - len(str(nobsgroups))) + '\n')
        icount = 3
        for line in range(icount+1,len(lines)):
            f.write(lines[line])
            if lines[line] == "* parameter groups\n":
                icount=line
                break
        for pargroup in upargroups:
            for item in pargroup:
                f.write(str(item) + " " * (13 - len(str(item))))
            f.write('\n')
        icount=icount+npargroups
        for line in range(icount+1, len(lines)):
            f.write(lines[line])
            if lines[line] == "* parameter data\n":
                icount=line
                break
        for i in range(icount + 1, len(lines)):
            if i < icount + 1 + npar:
                paritems = lines[i].split()
                par = paritems[0]
                for pargroup in upargroups:
                    if par == pargroup[0]:
                        upargroup = pargroup[0]
                    elif par.rstrip('0123456789') == pargroup[0]:
                        upargroup = pargroup[0]
                f.write(paritems[0]+" "*(13-len(paritems[0])))
                f.write(paritems[1]+" "*(13-len(paritems[0])))
                f.write(paritems[2]+" "*(13-len(paritems[0])))
                for item in range(3,6):
                    f.write(paritems[item]+" "*(13-len(paritems[item])))
                f.write(upargroup+" "*(13-len(upargroup)))
                for item in range(7,10):
                    f.write(paritems[item] + " " * (13 - len(paritems[item])))
                f.write('\n')
            else:
                f.write(lines[i])
    f.close()

    os.chdir(cwd)

    return new_pst,upargroups

def pstpardata(model_ws, or_pst,pardata, new_pst,pargroups_opt=True):
    """
    update the parameter initial values and bounds of a pst file

    :param or_pst: original pst file
    :param pardata: parameter group tags with initial values, lower and upper bounds
    :param new_pst: new pst with updated bounds
    :param pargroups: option whether pardata is structured as dictionary of parameter groups or parameter data
    :return: pst file
    """

    cwd = os.getcwd()

    os.chdir(model_ws)

    with open(or_pst,'r') as f:
        lines = f.readlines()
    f.close()

    iline = 0

    with open(new_pst,'w') as f:
        for line in range(len(lines)):
            f.write(lines[line])
            if lines[line] == "* parameter data\n":
                iline=line
                break
        if pargroups_opt:
            for i in range(iline+1,iline+1+int(lines[3].split()[0])):
                pargroup = lines[i].split()[6]
                match=0
                for par,data in pardata.items():
                    if pargroup == par:
                        match=1
                        paritems = lines[i].split()
                        f.write(paritems[0]+" "*(14-len(paritems[0])))
                        f.write(str(data[0]) + " " * (14 - len(str(data[0]))))
                        f.write(str(data[1])+" "*(14-len(str(data[1]))))
                        f.write(str(data[2])+" "*(14-len(str(data[2]))))
                        f.write(str(data[3]) + " " * (14 - len(str(data[3]))))
                        f.write(str(data[4])+" "*(14-len(str(data[4]))))
                        f.write(par+" "*(14-len(par)))
                        f.write(str(data[5])+" "*(14-len(str(data[5]))))
                        f.write(str(data[6])+" "*(14-len(str(data[6]))))
                        f.write(str(data[7])+" "*(14-len(str(data[7]))))
                        f.write('\n')
                if match==0:
                    f.write(lines[i])
            for line in range(iline+1+int(lines[3].split()[0]),len(lines)):
                f.write(lines[line])
        else:
            for i in range(iline+1,iline+1+int(lines[3].split()[0])):
                ipar = lines[i].split()[0]
                match=0
                for par,data in pardata.items():
                    if ipar == par:
                        match=1
                        paritems = lines[i].split()
                        for item in range(3):
                            f.write(paritems[item]+" "*(14-len(paritems[item])))
                        f.write(str(data[0]) + " " * (14 - len(str(data[0]))))
                        f.write(str(data[1])+" "*(14-len(str(data[1]))))
                        f.write(str(data[2])+" "*(14-len(str(data[2]))))
                        for item in range(6,10):
                            f.write(paritems[item]+" "*(14-len(paritems[item])))
                        f.write('\n')
                if match==0:
                    f.write(lines[i])
            for line in range(iline+1+int(lines[3].split()[0]),len(lines)):
                f.write(lines[line])

    os.chdir(cwd)

    return new_pst

def pstobswt(model_ws,or_pst,obsgroup_name, factor, new_pst):
    """
    Assigns weights of zero to the selected obsgroup
    :param or_pst: original pst file
    :param obsgroup_name: observation group to assign weight of zero
    :param factor: factor to apply to original weights for observations not in obsgroup_name
    :param new_pst: new pst file
    :return: pst file
    """
    cwd = os.getcwd()
    os.chdir(model_ws)

    with open(or_pst,'r') as f:
        lines = f.readlines()

    iline = 0

    with open(new_pst,'w') as f:
        for line in range(len(lines)):
            f.write(lines[line])
            if lines[line] == "* observation data\n":
                iline=line
                break
        for i in range(iline + 1, iline + 1 + int(lines[3].split()[1])):
            obsgroup = lines[i].split()[3]
            obs_items = lines[i].split()
            for item in range(2):
                f.write(obs_items[item] + " " * (17 - len(obs_items[item])))
            if obsgroup == obsgroup_name:
                f.write("0"+" "*13)
            else:
                new_weight = float(factor)*float(obs_items[2])
                f.write(str(new_weight) + " " * (17 - len(str(new_weight))))
            f.write(obs_items[3])
            f.write('\n')

        for line in range(iline+1+int(lines[3].split()[1]),len(lines)):
            f.write(lines[line])

    os.chdir(cwd)

    return new_pst

def pstobswt2(model_ws,or_pst,obsgroup_dict, new_pst):
    """
    Assigns weights to selected obsgroups
    :param or_pst: original pst file
    :param obsgroup_dict: dictionary of observation groups and associated weights
    :param new_pst: new pst file
    :return: pst file
    """
    cwd = os.getcwd()
    os.chdir(model_ws)

    with open(or_pst,'r') as f:
        lines = f.readlines()

    iline = 0

    with open(new_pst,'w') as f:
        for line in range(len(lines)):
            f.write(lines[line])
            if lines[line] == "* observation data\n":
                iline=line
                break
        for i in range(iline + 1, iline + 1 + int(lines[3].split()[1])):
            obs_items = lines[i].split()
            obsgroup = obs_items[3]
            for item in range(2):
                f.write(obs_items[item] + " " * (18 - len(obs_items[item])))
            match = 0
            for group, weight in obsgroup_dict.items():
                if group == obsgroup:
                    f.write(str(weight) + " " * (18 - len(str(weight))))
                    match = 1
            if match == 0:
                f.write(obs_items[2] + " " * (18 - len(obs_items[2])))
            f.write(obs_items[3])
            f.write('\n')

        for line in range(iline+1+int(lines[3].split()[1]),len(lines)):
            f.write(lines[line])

    os.chdir(cwd)

    return new_pst

def ppcov(model_ws,par_geostats,param_file=None):
    """
    create cov matrix for pilot points

    :param pp_file:
    :param par_geostats:
    :return: cov matrix filenames
    """

    cov_filenames = []

    cwd = os.getcwd()

    os.chdir(model_ws)

    for pp_par,geost in par_geostats.items():
        struct_filename = "struct_"+pp_par+".dat"
        ins_filename = "ppcov_"+pp_par+".in"

        zones = []

        with open(geost[0],'r') as g:
            lines = g.readlines()
        g.close()

        temp_pp_file = "temp_geos.dat"

        with open(temp_pp_file,"w") as f:

            #The number of zones are obtained:

            for line in lines:
                items = line.split()
                ix = items[1]
                iy = items[2]
                izone = int(items[3])
                ivalue = items[4]
                iname = items[5]
                f.write(f"{iname} {ix} {iy} {izone} {ivalue}\n")
                rep = 0
                if len(zones) > 0:
                    for i in range(len(zones)):
                        if zones[i]==izone:
                            rep=1
                    if rep==0:
                        zones.append(izone)
                else:
                    zones.append(izone)

        f.close()

        with open(struct_filename, 'w') as f:
            f.write("STRUCTURE "+pp_par+'\n')
            f.write("  NUGGET 0.0" +'\n')
            f.write("  TRANSFORM "+ geost[1] + '\n')
            f.write("  NUMVARIOGRAM 1" + '\n')
            f.write("  VARIOGRAM vario1 "+str(geost[2]) + '\n')
            f.write("END STRUCTURE" + '\n')
            f.write('\n')
            f.write("VARIOGRAM vario1"+'\n')
            f.write("  VARTYPE 2" + '\n')
            f.write("  BEARING 0" + '\n')
            f.write("  A " +str(geost[3]) + '\n')
            f.write("  ANISOTROPY 1.0" + '\n')
            f.write("END VARIOGRAM" + '\n')
        f.close()

        with open(ins_filename, 'w') as f:
            f.write(temp_pp_file +'\n')
            f.write("0" + '\n')
            f.write(struct_filename+ '\n')
            for izone in range(len(zones)):
                f.write(pp_par + '\n')
            f.write(pp_par+"_cov.dat"+ '\n')
            f.write("\n")
        f.close()

        exe_instruction = "ppcov.exe < "+ins_filename

        cov_filenames.append(pp_par+"_cov.dat")

        os.system(exe_instruction)

    os.chdir(cwd)

    if param_file != None:

        with open(param_file, 'a') as f:
            for cov_filename in cov_filenames:
                f.write("START COVARIANCE_MATRIX\n")
                f.write("file "+cov_filename+"\n")
                f.write("END COVARIANCE_MATRIX\n")
        f.close()

    return cov_filenames

def addreg2(model_ws,or_pst, phimlim, new_pst):
    """
    Low tech wrapper for addreg2.exe

    :param or_pst: original pst
    :param phimlim: low limit of acceptable objective function for PEST
    :param new_pst: new pst file
    :return:
    """

    cwd = os.getcwd()

    os.chdir(model_ws)

    addreg2_instruction = "addreg2.exe"+" "+or_pst+" "+new_pst+" "+str(phimlim)+" 0.1"

    os.system(addreg2_instruction)

    os.chdir(cwd)

    return new_pst

def addcovmat(model_ws, or_pst, cov_files, new_pst):
    """
    Low-tech wrapper for addcovmat.exe
    :param or_pst:
    :param cov_files:
    :param new_pst:
    :return:
    """

    cwd = os.getcwd()

    os.chdir(model_ws)

    covmatfile = "covmatfile.dat"

    with open(covmatfile, 'w') as f:
        f.write("# observation_group_name covariance_matrix_file"+'\n')
        for cov_file in cov_files:
            f.write("regul_"+cov_file.split('_cov')[0]+" "+cov_file+'\n')

    addcovmat_ins = "addcovmat.exe "+or_pst+" "+covmatfile+" "+new_pst

    os.system(addcovmat_ins)

    os.chdir(cwd)

    return new_pst

def initbatchfile(model_ws,modelname, model_version=None,batch_file=None):
    """
    
    Simple function to create a model batch file

    Args:
        model_ws('str'): working folders
        modelname('str'): model name
        model_version('str'): model version (only for mf6 the mass balance file has a different extension)
        batch_file('str'): batch file name

    Returns:
        'str': name of batch file
    """

    if batch_file == None:
        batch_file = "run_model.bat"

    with open(os.path.join(model_ws,batch_file), 'w') as f:
        f.write("@echo off"+'\n')
        f.write('\n')
        f.write("del " + modelname + ".hds" + " > nul"+'\n')
        if model_version == "mf6":
            f.write("del " + modelname + ".bud" + " > nul" + '\n')
        else:
            f.write("del " + modelname + ".cbb" + " > nul" + '\n')

    f.close()

    return batch_file

def addbatchfile(model_ws,instruction, batch_file):

    with open(os.path.join(model_ws,batch_file), 'a') as f:
        f.write('\n')
        f.write(instruction+" > nul"+'\n')

    f.close()

    return batch_file

def mf6mod2obs_in(model_ws,interp_file, headobsfile, 
                    hdsbinaryfile, distype, nlay, 
                    time_units, initial_date, ext_time, 
                    headsimfile):

    instruction_file = headsimfile.split('.')[0]+".in"

    with open(os.path.join(model_ws,instruction_file), 'w') as f:
        f.write(interp_file+'\n')
        f.write(interp_file + '\n')
        f.write("y" + '\n')
        f.write(headobsfile + '\n')
        f.write(hdsbinaryfile + '\n')
        f.write(" "+'\n')
        f.write(" " + '\n')
        f.write(distype + '\n')
        f.write(str(nlay) + '\n')
        f.write(time_units + '\n')
        f.write(initial_date + '\n')
        f.write("00:00:00" + '\n')
        f.write(str(ext_time) + '\n')
        f.write(headsimfile + '\n')

    return instruction_file

def mfmod2obs_in(model_ws,gsf_file, coord, welllist, headobsfile,hdsbinaryfile,thresh, initialdate, nlay,extrap, headsimfile,precision=None):
    """generate all inputs required to run mod2obs

    Args:
        model_ws (str): working folder where all the necessary files are located
        gsf_file (str): grid specification file name
        coord (str): well coordinate file name (PEST-style)
        welllist (str): well list file name (PEST-style)
        headobsfile (str): observed head/conc file name (PEST-style)
        hdsbinaryfile (str): model head (hds) output file name
        thresh (float): inactive cell/dry cell threshold
        initialdate (str): initial date of simulation in dd/mm/yyyy format
        nlay (int): number of model layers
        extrap (float): extrapolation (days) for simulated head/conc calculation out of simulated time range
        headobsfile (str): simulated head/conc file name (PEST-style)
        precision (str, optional): model output precision ("s": single, "d": double). Defaults to None ("s": single).

    Returns:
        str: instruction_file name (also generated in the working folder)
    """

    instruction_file = headsimfile.split('.')[0]+".in"

    with open(os.path.join(model_ws,instruction_file), 'w') as f:
        f.write(gsf_file+'\n')
        f.write(coord + '\n')
        f.write(welllist + '\n')
        f.write(headobsfile + '\n')
        f.write(hdsbinaryfile + '\n')
        f.write("f" + '\n')
        f.write(str(thresh)+'\n')
        f.write("d" + '\n')
        f.write(initialdate + '\n')
        f.write("00:00:00" + '\n')
        f.write(str(nlay) + '\n')
        f.write(str(extrap) + '\n')
        f.write(headsimfile + '\n')

    cwd = os.getcwd()

    os.chdir(model_ws)

    if precision == "d":
        os.system("mod2obs_dbl.exe < "+instruction_file+" > nul")
    else:
        os.system("mod2obs_dbl.exe < "+instruction_file+" > nul")

    os.chdir(cwd)

    return instruction_file

def smpdiff_in(model_ws,obsfile,welllist,dobsfile):

    instruction_file = dobsfile.split('.')[0]+".in"

    with open(os.path.join(model_ws,instruction_file), 'w') as f:
        f.write(obsfile+'\n')
        f.write(welllist + '\n')
        f.write(dobsfile + '\n')
        f.write("p" + '\n')
        f.write("n" + '\n')

    cwd = os.getcwd()

    os.chdir(model_ws)

    os.system("smpdiff.exe < "+instruction_file)

    os.chdir(cwd)

    return instruction_file

def pstregwt(model_ws, or_pst,reggroups, new_pst,regcontinue=False):
    """
    Assigns weights to the selected reggroups
    :param or_pst: original pst
    :param reggroups: str list regularization groups to which assign weight of zero
    :param new_pst: new pst with the updated reg weights
    :return: new_pst
    """
    with open(os.path.join(model_ws,or_pst),'r') as f:
        lines = f.readlines()

    iline = 0

    with open(os.path.join(model_ws,new_pst),'w') as f:
        for line in range(len(lines)):
            f.write(lines[line])
            if lines[line] == "* prior information\n":
                iline=line
                break
        for i in range(iline + 1, iline + 1 + int(lines[3].split()[3])):
            reggroup = lines[i].split()[7]
            reg_items = lines[i].split()
            for item in range(6):
                f.write(reg_items[item] + " " )
            j=0
            for igroup in reggroups:
                if reggroup == igroup[0]:
                    f.write(str(igroup[1])+" "+reg_items[7]+'\n')
                    j = 1
            if j == 0:
                    f.write(reg_items[6]+" "+reg_items[7]+'\n')
        if regcontinue:
            for line in range(iline+1+int(lines[3].split()[3]),len(lines)-2):
                f.write(lines[line])
            f.write("1.0 1.0e-10 1.0e10 CONTINUE\n")
        else:
            for line in range(iline+1+int(lines[3].split()[3]),len(lines)-1):
                f.write(lines[line])
        f.write(" 1.3   1.0e-2     0")

    return new_pst

def start_workers(pstfile,worker_dir,num_workers=None,worker_root="..",exec='PEST_HP',cleanup=True):
    """
    This is an extremely simplified replicated version of the Pyemu start_workers function
    Included in os_utils.py

    :param pstfile: name of the pst file
    :param worker_dir: relative path of the model and PEST files from the current working directory
    :param num_workers: number of workers. If None then the default is the number of core of the computer
    :param worker_root: absolute path where agents should be copied in
    :param cleanup: option to delete agent folders once the PEST run finish
    :return:
    """

    if not os.path.isdir(worker_dir):
        raise Exception("worker dir '{0}' not found".format(worker_dir))
    if not os.path.isdir(worker_root):
        raise Exception("worker root dir not found")
    if num_workers is None:
        num_workers = mp.cpu_count()
    else:
        num_workers = int(num_workers)

    hostname = socket.gethostname()
    base_dir = os.getcwd()

    os.chdir(worker_dir)
    
    worker_dir = os.getcwd()

    port = int(4004)

    args = [exec, pstfile, "/h", ":{0}".format(port)]

    stdout = open(os.devnull, "w")
    master_p = sp.Popen(args, stdout=stdout)

    time.sleep(1.5)

    tcp_arg = "{0}:{1}".format(hostname, port)
    procs = []
    worker_dirs = []
    for i in range(num_workers):
        new_worker_dir = os.path.join(worker_root, "worker_{0}".format(i))
        if os.path.exists(new_worker_dir):
            shutil.rmtree(new_worker_dir)
        shutil.copytree('.', new_worker_dir)

        args = [exec, pstfile, "/h", tcp_arg]
        cwd = new_worker_dir

        os.chdir(cwd)
        with open(os.devnull, "w") as f:
            p = sp.Popen(args, stdout=f, stderr=f)
        procs.append(p)
        os.chdir(worker_dir)
        worker_dirs.append(new_worker_dir)

    master_p.wait()
    time.sleep(1.5)

    for p in procs:
        p.kill()
    for p in procs:
        p.wait()
    if cleanup:
        cleanit = 0
        while len(worker_dirs) > 0 and cleanit < 100000:  # arbitrary 100000 limit
            cleanit = cleanit + 1
            for d in worker_dirs:
                shutil.rmtree(d)
                worker_dirs.pop(worker_dirs.index(d))  # if successfully removed

    os.chdir(base_dir)   

def pest_hp_settings(model_ws,or_pst,settings, new_pst):
    """
    Adds pest and pest_hp settings control data section. Currently available:
    5th line - PRECIS
    6th line - UPTESTMIN=25, DERFORGIVE
    7th line - ABSPARMAX
    10th line - JCOSAVEITN, REISAVEITN, PARSAVEITN

    :param or_pst: original pst file
    :param settings: list of strings that declare the pest_hp instructions
    :param new_pst: new pst with the pest_hp instructions included in it
    :return:
    """
    with open(os.path.join(model_ws,or_pst),'r') as f:
        lines = f.readlines()
    f.close()

    with open(os.path.join(model_ws,new_pst),'w') as f:
        for iline in range(len(lines)):
            if iline == 4:
                aux = 2
                itext = lines[iline].rstrip()
                items = itext.split()
                for item in range(2):
                    f.write(items[item]+" ")
                for setting in settings:
                    isetting = setting.split('=')
                    if isetting[0].lower()=='precis':
                        f.write(isetting[1]+" ")
                        aux = 3
                for item in range(aux,len(items)):
                    f.write(items[item]+" ")
                f.write('\n')
            elif iline == 5:
                itext = lines[iline].rstrip()
                items = itext.split()
                for item in range(len(items)):
                    f.write(items[item]+" ")
                for setting in settings:
                    isetting = setting.split('=')
                    if isetting[0].lower()=='uptestmin':
                        f.write(setting+" ")
                    if isetting[0].lower() == 'derforgive':
                        f.write(setting+" ")
                f.write('\n')
            elif iline == 6:
                itext = lines[iline].rstrip()
                f.write(itext+" ")
                for setting in settings:
                    if str.lower('ABSPARMAX') in setting.lower():
                        f.write(setting+" ") 
                f.write('\n')
            elif iline == 9:
                itext = lines[iline].rstrip()
                f.write(itext+" ")
                for setting in settings:
                   if setting.lower() == 'jcosaveitn':
                      f.write(setting+" ") 
                   if setting.lower() == 'reisaveitn':
                      f.write(setting+" ") 
                   if setting.lower() == 'parsaveitn':
                      f.write(setting+" ")
                f.write('\n')
            else:
                f.write(lines[iline])

    return new_pst

def pstpargrouptied(model_ws, or_pst,pargrouptied, new_pst):
    """
    pargrouptied = [[pargroup1,pargroup2],
                    [pargroup3,pargroup4]]

    Args:
        model_ws ([type]): [description]
        or_pst ([type]): [description]
        pardata ([type]): [description]
        new_pst ([type]): [description]
    """

    cwd = os.getcwd()

    os.chdir(model_ws)

    with open(or_pst,'r') as f:
        lines = f.readlines()
    f.close()

    iline = 0

    for line in range(len(lines)):
        if lines[line] == "* parameter data\n":
            iline=line
            break

    pardata=[]

    for i in range(iline+1,iline+1+int(lines[3].split()[0])):
        PARNME =  lines[i].split()[0]
        PARTRANS =  lines[i].split()[1]
        PARCHGLIM =  lines[i].split()[2]
        PARVAL1 =  lines[i].split()[3]
        PARLBND =  lines[i].split()[4]
        PARUBND =  lines[i].split()[5]
        PARGP = lines[i].split()[6]
        SCALE = lines[i].split()[7]
        OFFSET = lines[i].split()[8]
        DERCOM = lines[i].split()[9]

        ipardata = [PARNME,PARTRANS,PARCHGLIM,PARVAL1,PARLBND,PARUBND,PARGP,SCALE,OFFSET,DERCOM]

        pardata.append(ipardata)

        tied_params = []

    for ipargrouptied in pargrouptied:
        tied_params1 = []
        tied_params2 = []
        for ipardata in pardata:
            if ipardata[6] == ipargrouptied[0]:
                tied_params1.append(ipardata[0])
        for ipardata in pardata:
            if ipardata[6] == ipargrouptied[1]:
                tied_params2.append(ipardata[0])
        for i in range(len(tied_params1)):
            tied_params.append([tied_params1[i],tied_params2[i]])


    iline = 0

    with open(new_pst,'w') as f:
        for line in range(len(lines)):
            f.write(lines[line])
            if lines[line] == "* parameter data\n":
                iline=line
                break
        icount = 0
        for i in range(iline+1,iline+1+int(lines[3].split()[0])):
            match=0
            for ipargrouptied in pargrouptied:
                if pardata[icount][6] == ipargrouptied[0]:
                    match=1
                    f.write(pardata[icount][0] + " " * (14 - len(pardata[icount][0])))
                    f.write("tied" + " " * (14 - len("tied")))
                    for j in range(2,len(pardata[icount])):
                        f.write(pardata[icount][j] + " " * (14 - len(pardata[icount][j])))
                    f.write('\n')
            if match==0:
                f.write(lines[i])
            icount = icount+1
        for itiedparam in tied_params:
            f.write(itiedparam[0]+ " " + itiedparam[1]+"\n")
        for line in range(iline+1+int(lines[3].split()[0]),len(lines)):
            f.write(lines[line])
    os.chdir(cwd)
    return new_pst

def create_settings_file(sim,pest_dir):
    """
    Function creates settings file and Grid Specification File for a structured modflow model
        args:
            sim = modflow model (obj)
            pest_dir = pest files directory

        return:
            array of settings and gsf file names
    """

    nrow = sim.nrow
    ncol = sim.ncol
    delr = sim.modelgrid.delr
    delc = sim.modelgrid.delc

    D = sim.modelgrid.delc.sum()
    Dx = D*np.cos(np.pi/2-sim.modelgrid.angrot_radians)
    Dy = D*np.sin(np.pi/2-sim.modelgrid.angrot_radians)

    xul = sim.modelgrid.xoffset+Dx
    yul = sim.modelgrid.yoffset+Dy
    

    filename = "settings.fig"
    with open(os.path.join(pest_dir,filename), 'w') as f:
        f.write("colrow=no"+'\n')
        f.write("date=dd/mm/yyyy")
    f.close()
    gsf_filename = sim.name+".gsf"
    with open(os.path.join(pest_dir,gsf_filename), 'w') as f:
        f.write(str(nrow)+" "+str(ncol)+"\n")
        f.write(str(xul)+" "+str(yul)+" "+ str(sim.modelgrid.angrot_radians)+"\n")
        if np.all(delr == delr[0]):
            f.write(str(sim.ncol)+"*"+str(delr[0])+"\n")
        else:
            for i in range(ncol):
                f.write(delr[i]+" ")
        if np.all(delc == delc[0]):        
            f.write(str(sim.nrow)+"*"+str(delc[0])+"\n")
        else:
            for i in range(nrow):
                f.write(delc[i]+" ")
    f.close()

    return filename,gsf_filename

def well_bc_tpl(dir,sim,disc_neg=False,joint_sp=True):
    """
    Generates par2par well_bc tpl file to apply multipliers on well_bc flows
    """

    lat_rch_df = sim.wel.stress_period_data.df

    cb_un = sim.wel.ipakcb
    wel_options = sim.wel.options 
    # could not find where the AUTOFLOWREDUCE option is saved. It is assumed that this option is active.
    heading = '# WEL package for  MODFLOW-USG, replicated for PEST.'

    mxact = sim.wel.stress_period_data.mxact

    aux = wel_options[0].split()[len(wel_options[0].split())-1]

    t_cumsum = sim.dis.perlen.array.cumsum()

    if disc_neg:
        # check iwel tags with neg flows
        iwel_list = []
        iwel_groups = lat_rch_df[lat_rch_df['flux']>0][aux].unique()
    else:
        iwel_groups = lat_rch_df[aux].unique()

    tloc_filename = "wel_tloc.dat"
    f_pth3 = os.path.join(dir,tloc_filename)
    tlocf = open(f_pth3,'w')

    wel_tpl_pars = []

    if joint_sp:


        wel_tpl_file = "wel.tpl"

        tpl_filename = "par2par_wel.tpl"
        dat_filename = "par2par_wel.dat"

        f_pth1 = os.path.join(dir,wel_tpl_file)
        f_pth2 = os.path.join(dir,tpl_filename)
        

        wf = open(f_pth1,'w')
        pwf = open(f_pth2,'w')
        

        wf.write("ptf ~\n")
        wf.write("%s\n" % heading)
        line = " {0:9d} {1:9d} ".format(mxact, cb_un)+" AUTOFLOWREDUCE "+wel_options[0]
        wf.write(line+"\n")

        pwf.write("ptf ~\n")
        pwf.write("* parameter data\n")

        index = 1 
        for iwel in iwel_groups:
            for iper in range(sim.nper):
                parname_tx = str(int(iwel))+"_wm"+str(iper+1)
                wel_tpl_pars.append(parname_tx)
                itpl = "~" + " " * (13 - len(parname_tx)) + parname_tx + "~"
                pwf.write(parname_tx+" = " + itpl+"\n")

                tlocf.write(" {0:9d} {1:7.2f} {2:7.2f} {3:7d} {4:7.2f} {5:s}\n".format(index,
                                                                            0,
                                                                            t_cumsum[iper],
                                                                            int(iwel),
                                                                            0,
                                                                            parname_tx))
                index = index+1

        ipar = 1
        for iper in range(sim.nper):
            iper_df = lat_rch_df[lat_rch_df['per']==iper]
            iper_mxact = len(iper_df)
            wf.write(" {0:9d} {1:9d} # stress period {2:d}\n".format(iper_mxact, 0, iper + 1))
            ilays = iper_df['k'].values
            irows = iper_df['i'].values
            icols = iper_df['j'].values
            iflux = iper_df['flux'].values
            iiwels = iper_df['iwel'].values
            for iact in range(iper_mxact):
                parname_tx = "ipar"+str(ipar)
                itpl = "~" + " " * (13 - len(parname_tx)) + parname_tx + "~"
                if disc_neg:
                    if iflux[iact]>0:
                        wf.write(" {0:9d} {1:9d} {2:9d} {3:s} {4:9d}\n".format(ilays[iact]+1,
                                                        irows[iact]+1,
                                                        icols[iact]+1,
                                                        itpl,
                                                        int(iiwels[iact])))
                        pwf.write(" {0:s} = {1:f} * {2:s}\n".format(parname_tx
                                                        ,iflux[iact],
                                                        str(int(iiwels[iact]))+"_wm"+str(iper+1)))
                        ipar=ipar+1
                    else:
                        wf.write(" {0:9d} {1:9d} {2:9d} {3:15.5f} {4:9d}\n".format(ilays[iact]+1,
                                                        irows[iact]+1,
                                                        icols[iact]+1,
                                                        iflux[iact],
                                                        int(iiwels[iact])))
                else:
                    wf.write(" {0:9d} {1:9d} {2:9d} {3:s} {4:9d}\n".format(ilays[iact]+1,
                                                        irows[iact]+1,
                                                        icols[iact]+1,
                                                        itpl,
                                                        int(iiwels[iact])))
                    pwf.write(" {0:s} = {1:f} * {2:s}\n".format(parname_tx,
                                                            iflux[iact],
                                                            str(int(iiwels[iact]))+"_wm"+str(iper+1)))
                    ipar=ipar+1
        wf.close()
            
        pwf.write("* template and model input files\n")
        pwf.write(wel_tpl_file+" "+sim.wel.file_name[0])

        pwf.close()

        

    else:

        for iper in range(sim.nper):

            wel_tpl_file = "wel_"+str(iper+1)+".tpl"
            tpl_filename = "par2par_wel_"+str(iper+1)+".tpl"
            dat_filename = "par2par_wel-"+str(iper+1)+".dat"

            f_pth1 = os.path.join(dir,wel_tpl_file)
            f_pth2 = os.path.join(dir,tpl_filename)
        

            wf = open(f_pth1,'w')
            pwf = open(f_pth2,'w')

            wf.write("ptf ~\n")
            wf.write("%s\n" % heading)
            line = " {0:9d} {1:9d} ".format(mxact, cb_un)+" AUTOFLOWREDUCE "+wel_options[0]
            wf.write(line+"\n")

            pwf.write("ptf ~\n")
            pwf.write("* parameter data\n")

            index = 1 
            for iwel in iwel_groups:
                parname_tx = str(int(iwel))+"_wm"+str(iper+1)
                wel_tpl_pars.append(parname_tx)
                itpl = "~" + " " * (13 - len(parname_tx)) + parname_tx + "~"
                pwf.write(parname_tx+" = " + itpl+"\n")

                tlocf.write(" {0:9d} {1:7.2f} {2:7.2f} {3:7d} {4:7.2f} {5:s}\n".format(index,
                                                                            0,
                                                                            t_cumsum[iper],
                                                                            int(iwel),
                                                                            0,
                                                                            parname_tx))
                index = index+1

            ipar = 1
            iper_df = lat_rch_df[lat_rch_df['per']==iper]
            iper_mxact = len(iper_df)
            wf.write(" {0:9d} {1:9d} # stress period {2:d}\n".format(iper_mxact, 0, iper + 1))
            ilays = iper_df['k'].values
            irows = iper_df['i'].values
            icols = iper_df['j'].values
            iflux = iper_df['flux'].values
            iiwels = iper_df['iwel'].values
            for iact in range(iper_mxact):
                parname_tx = "ipar"+str(ipar)
                itpl = "~" + " " * (13 - len(parname_tx)) + parname_tx + "~"
                if disc_neg:
                    if iflux[iact]>0:
                        wf.write(" {0:9d} {1:9d} {2:9d} {3:s} {4:9d}\n".format(ilays[iact]+1,
                                                        irows[iact]+1,
                                                        icols[iact]+1,
                                                        itpl,
                                                        int(iiwels[iact])))
                        pwf.write(" {0:s} = {1:f} * {2:s}\n".format(parname_tx
                                                        ,iflux[iact],
                                                        str(int(iiwels[iact]))+"_wm"+str(iper+1)))
                        ipar=ipar+1
                    else:
                        wf.write(" {0:9d} {1:9d} {2:9d} {3:15.5f} {4:9d}\n".format(ilays[iact]+1,
                                                        irows[iact]+1,
                                                        icols[iact]+1,
                                                        iflux[iact],
                                                        int(iiwels[iact])))
                else:
                    wf.write(" {0:9d} {1:9d} {2:9d} {3:s} {4:9d}\n".format(ilays[iact]+1,
                                                        irows[iact]+1,
                                                        icols[iact]+1,
                                                        itpl,
                                                        int(iiwels[iact])))
                    pwf.write(" {0:s} = {1:f} * {2:s}\n".format(parname_tx,
                                                            iflux[iact],
                                                            str(int(iiwels[iact]))+"_wm"+str(iper+1)))
                    ipar=ipar+1
            wf.close()
            
            pwf.write("* template and model input files\n")
            pwf.write(wel_tpl_file+" "+sim.wel.file_name[0])

            pwf.close()



    tlocf.close()


    return tpl_filename,dat_filename,tloc_filename,wel_tpl_pars

def rech_pars(dir,sim, rch_zone_file,rch_rts_file,rts_unit_number):

    rch_tpl_file = "rch.tpl"
    rch_rts_tpl_file = "rts.tpl"

    tpls = [rch_tpl_file,rch_rts_tpl_file]
    dats = [sim.rch.file_name,rch_rts_file]

    rch_zone_array = np.reshape(np.loadtxt(os.path.join(dir,rch_zone_file)),(sim.nrow,sim.ncol))

    rch_zones = np.unique(rch_zone_array)

    with open(os.path.join(dir,rch_tpl_file),"w") as f:
        f.write("ptf ~\n")
        f.write("# MODFLOW-USGs Recharge Package\n")
        f.write(f"1 0 RTS {len(rch_zones)}\n")
        f.write(f"1 INRCHZONES {len(rch_zones)}\n")
        f.write("CONSTANT 1.0\n")
        f.write("OPEN/CLOSE "+rch_zone_file+" 1 (FREE) -1\n")
        if sim.nper>1:
            for i in range(1,sim.nper):
                f.write("-1 INRCHZONES -1\n")
    f.close()

    rts_nam = False

    with open(os.path.join(dir,sim.namefile),"r") as f:
        lines = f.readlines()
        for line in lines:
            if str.lower(line.split()[0])=="rts":
                rts_nam = True
    f.close()

    if not rts_nam:
        with open(os.path.join(dir,sim.namefile),"a") as f:
            f.write("RTS {0:3d} {1:s}\n".format(rts_unit_number,rch_rts_file))
        f.close()

    # it is assumed for now that the RTS file is properly writen

    rf = open(os.path.join(dir,rch_rts_file),"r")
    rts_lines = rf.readlines()
    rf.close()

    prf = open(os.path.join(dir,rch_rts_tpl_file),"w")

    prf.write("ptf ~\n")

    pars = []


    for i,line in enumerate(rts_lines):
        line_sp = line.split()
        prf.write(" {0:7.2f} {1:7.2f} ".format(float(line_sp[0]),float(line_sp[1])))
        index = 1
        for j in range(2,len(line_sp),2):
            parname_tx = str(i+1)+"rf"+str(index)
            pars.append(parname_tx)
            itpl = "~" + " " * (13 - len(parname_tx)) + parname_tx + "~"
            prf.write(" {0:15.10f} {1:s}".format(float(line_sp[j]),itpl))
            index = index +1
        prf.write("\n")
    prf.close()

    return tpls,dats,pars

def ets_openclose(dir,sim,ET_zones,ET_params_dict):

    nrow = sim.nrow
    ncol = sim.ncol
    ET_zones_rs = np.reshape(ET_zones,nrow*ncol)
    ET_rate = np.zeros(nrow*ncol,dtype=float)
    ET_ed = np.zeros(nrow*ncol,dtype=float)

    nseg_ = len(ET_params_dict[0][2])

    ET_pxdp = np.zeros((nseg_,nrow*ncol),dtype=float)
    ET_petm = np.zeros((nseg_,nrow*ncol),dtype=float)

    for i,izone in enumerate(ET_zones_rs):
        ET_rate[i] = ET_params_dict[izone][0]
        ET_ed[i] = ET_params_dict[izone][1]
        pxdp = ET_params_dict[izone][2]
        petm = ET_params_dict[izone][3]
        for j in range(len(pxdp)):
            ET_pxdp[j][i] =  pxdp[j]
            ET_petm[j][i] =  petm[j]

    ET_surface = sim.dis.gettop()
    ET_rate = np.reshape(ET_rate,(nrow,ncol))
    ET_ed = np.reshape(ET_ed,(nrow,ncol))
    ET_pxdp = np.reshape(ET_pxdp,(nseg_,nrow,ncol))
    ET_petm = np.reshape(ET_petm,(nseg_,nrow,ncol))

    ET_surface_file = "et_surf.dat"
    ET_rate_file = "et_rate.dat"
    ET_ed_file = "et_ed.dat"

    f = open(os.path.join(dir,ET_rate_file),"w")
    np.savetxt(f, ET_rate)
    f.close()

    f = open(os.path.join(dir,ET_ed_file),"w")
    np.savetxt(f, ET_ed)
    f.close()

    f = open(os.path.join(dir,ET_surface_file),"w")
    np.savetxt(f, ET_surface)
    f.close()

    for i in range(nseg_):
        ET_pxdp_file = "et_pxtm_"+str(i+1)+".dat"
        ET_petm_file = "et_petm_"+str(i+1)+".dat"
        f1 = open(os.path.join(dir,ET_pxdp_file),"w")
        f2 = open(os.path.join(dir,ET_petm_file),"w") 
        np.savetxt(f1, ET_pxdp[i])
        f1.close()
        np.savetxt(f2, ET_petm[i])
        f2.close()

    ets_file = sim.name+".ets"

    f = open(os.path.join(dir,ets_file),"w")

    with open(os.path.join(dir,ets_file),"w") as f:
        f.write("# MODFLOW-USGs ETS Package\n")
        f.write(" 1 50 0 "+str(nseg_+1)+"\n")
        f.write("1 1 1 -1 1\n")
        f.write("OPEN/CLOSE "+ET_surface_file+" 1 (FREE) -1\n")
        f.write("OPEN/CLOSE "+ET_rate_file+" 1 (FREE) -1\n")
        f.write("OPEN/CLOSE "+ET_ed_file+" 1 (FREE) -1\n")
        for i in range(nseg_):
            ET_pxdp_file = "et_pxtm_"+str(i+1)+".dat"
            ET_petm_file = "et_petm_"+str(i+1)+".dat"
            f.write("OPEN/CLOSE "+ET_pxdp_file+" 1 (FREE) -1\n")
            f.write("OPEN/CLOSE "+ET_petm_file+" 1 (FREE) -1\n")
        for i in range(1,sim.nper):
            f.write("-1 1 1 -1 1\n")
            f.write("OPEN/CLOSE "+ET_rate_file+" 1 (FREE) -1\n")
            f.write("OPEN/CLOSE "+ET_ed_file+" 1 (FREE) -1\n")
            for i in range(nseg_):
                ET_pxdp_file = "et_pxtm_"+str(i+1)+".dat"
                ET_petm_file = "et_petm_"+str(i+1)+".dat"
                f.write("OPEN/CLOSE "+ET_pxdp_file+" 1 (FREE) -1\n")
                f.write("OPEN/CLOSE "+ET_petm_file+" 1 (FREE) -1\n")
    f.close()

def bud2smp_in(model_ws,gsf_file,nlay,flow_binaryfile,max_output_times,flow_type,initialdate,zone_array,zone_id_dict,flowsimfile):
    """
    Generates the input for PEST utility bud2smp

    Args:
        model_ws (_type_): _description_
        gsf_file (_type_): _description_
        nlay (_type_): _description_
        cbb_binaryfile (_type_): _description_
        max_output_times (_type_): _description_
        flow_type (_type_): _description_
        initialdate (_type_): _description_
        pwell_zone_array (_type_): _description_
    """

    instruction_file = flowsimfile.split('.')[0]+".in"

    #save nlay zone files

    zone_files = []

    zones = np.unique(zone_array)

    for i,slice_2d in enumerate(zone_array):
        ifile = flowsimfile.split('.')[0]+"_zoneL"+str(i+1)+".dat"
        zone_files.append(ifile)
        with open(os.path.join(model_ws,ifile), 'w') as f:
            np.savetxt(f, slice_2d,fmt='%i')
        f.close()
     
    with open(os.path.join(model_ws,instruction_file), 'w') as f:
        f.write(gsf_file+'\n')
        f.write(str(nlay) + '\n')
        f.write(flow_binaryfile + '\n')
        f.write('9\n')
        f.write(str(max_output_times)+'\n')
        f.write(str(flow_type)+'\n')
        f.write(initialdate + '\n')
        f.write("00:00:00" + '\n')
        f.write("d" + '\n')
        for izone_file in zone_files:
            f.write(izone_file + '\n')
            f.write("f" + '\n')
        for izone in zones:
            if int(izone>0):
                f.write(zone_id_dict[izone]+'\n')
        f.write(flowsimfile + '\n')
        f.write("1" + '\n')
        f.write("f" + '\n')
        f.write('nul\n')
    f.close()

    cwd = os.getcwd()

    os.chdir(model_ws)

    os.system("bud2smp.exe < "+instruction_file)


    os.chdir(cwd)

    return instruction_file



    
    














